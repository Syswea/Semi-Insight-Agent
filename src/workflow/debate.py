"""
src/workflow/debate.py

å¤šä»£ç†è¾©è®ºæ¨¡å—ï¼šåŒ…å«è¾©è®ºèŠ‚ç‚¹å’ŒåŸºäº AutoGen çš„çœŸå®å¤šä»£ç†å¯¹æŠ—ã€‚
"""

import json
import logging
import re
import os
from typing import Dict, Any, List, Optional

import autogen
from langchain_core.messages import SystemMessage, AIMessage, HumanMessage
from llama_index.llms.openai_like import OpenAILike

from src.state import AgentState

logger = logging.getLogger(__name__)

# AutoGen é…ç½®
AUTOGEN_LLM_CONFIG = {
    "config_list": [
        {
            "model": os.getenv("LLM_MODEL", "qwen/qwen3-14b"),
            "base_url": os.getenv("OPENAI_API_BASE", "http://127.0.0.1:1234/v1"),
            "api_key": os.getenv("OPENAI_API_KEY", "lm-studio"),
        }
    ],
    "cache_seed": 42,
    "temperature": 0.7,
}


def run_autogen_debate(question: str, context: str) -> Dict[str, Any]:
    """
    è¿è¡Œå®Œæ•´çš„ AutoGen å¤šä»£ç†è¾©è®º
    """
    from src.agents.debate_agents import (
        BULLISH_SYSTEM_MESSAGE,
        BEARISH_SYSTEM_MESSAGE,
        JUDGE_SYSTEM_MESSAGE,
    )

    logger.info("[AutoGen] Initializing debate agents...")

    # 1. å®šä¹‰ Agents
    bullish_analyst = autogen.AssistantAgent(
        name="BullishAnalyst",
        system_message=BULLISH_SYSTEM_MESSAGE,
        llm_config=AUTOGEN_LLM_CONFIG,
    )

    bearish_analyst = autogen.AssistantAgent(
        name="BearishAnalyst",
        system_message=BEARISH_SYSTEM_MESSAGE,
        llm_config=AUTOGEN_LLM_CONFIG,
    )

    judge = autogen.AssistantAgent(
        name="JudgeAgent",
        system_message=JUDGE_SYSTEM_MESSAGE,
        llm_config=AUTOGEN_LLM_CONFIG,
    )

    user_proxy = autogen.UserProxyAgent(
        name="UserProxy",
        human_input_mode="NEVER",
        max_consecutive_auto_reply=3,
        is_termination_msg=lambda x: "TERMINATE" in (x.get("content") or ""),
        code_execution_config=False,
    )

    # 2. ç»„å»º GroupChat
    groupchat = autogen.GroupChat(
        agents=[user_proxy, bullish_analyst, bearish_analyst, judge],
        messages=[],
        max_round=6,
        speaker_selection_method="round_robin",
    )

    manager = autogen.GroupChatManager(
        groupchat=groupchat, llm_config=AUTOGEN_LLM_CONFIG
    )

    # 3. å¼€å§‹è¾©è®º
    debate_topic = f"Topic: {question}\n\nBackground Context: {context}\n\nPlease analyze this topic from your respective perspectives. Judge, provide the final structured JSON scores after everyone has spoken."

    logger.info("[AutoGen] Starting Group Chat...")
    user_proxy.initiate_chat(manager, message=debate_topic)

    # 4. æå–ç»“æœ
    debate_transcript = {}
    last_json = None

    for i, msg in enumerate(groupchat.messages):
        sender = msg.get("name", "Unknown")
        content = msg.get("content", "")
        debate_transcript[f"step_{i}_{sender}"] = content

        if sender == "JudgeAgent":
            try:
                clean_msg = re.sub(r"<think>.*?</think>", "", content, flags=re.DOTALL)
                if "```json" in clean_msg:
                    clean_msg = clean_msg.split("```json")[1].split("```")[0].strip()
                elif "```" in clean_msg:
                    clean_msg = clean_msg.split("```")[1].split("```")[0].strip()

                potential_json = json.loads(clean_msg.strip())
                if "bull_score" in potential_json:
                    last_json = potential_json
            except:
                continue

    if not last_json:
        # å›é€€é€»è¾‘
        logger.warning("[AutoGen] Judge failed to provide JSON, using default scores.")
        last_json = {
            "bull_score": 50,
            "bear_score": 50,
            "final_score": 50,
            "confidence": "low",
            "key_bull_points": ["åˆ†ææœªå®Œæˆ"],
            "key_bear_points": ["é£é™©è¯„ä¼°æœªå®Œæˆ"],
            "risk_level": "medium",
            "recommendation": "Hold",
        }

    return {
        "debate_transcript": debate_transcript,
        "scores": {
            "bull_score": last_json.get("bull_score", 50),
            "bear_score": last_json.get("bear_score", 50),
            "final_score": last_json.get("final_score", 50),
            "confidence": last_json.get("confidence", "medium"),
        },
        "key_points": {
            "bull": last_json.get("key_bull_points", []),
            "bear": last_json.get("key_bear_points", []),
        },
        "assessment": {
            "risk_level": last_json.get("risk_level", "medium"),
            "recommendation": last_json.get("recommendation", "Hold"),
        },
    }


def debate_node(state: AgentState) -> Dict[str, Any]:
    """
    è¾©è®ºæ‰§è¡ŒèŠ‚ç‚¹ï¼šè°ƒç”¨ AutoGen è¿›è¡Œå¤šä»£ç†å¯¹æŠ—ã€‚
    """
    logger.info("[Debate Node] Starting multi-agent debate with AutoGen...")

    messages = state.get("messages", [])

    # æå–ç”¨æˆ·é—®é¢˜
    user_question = None
    for msg in messages:
        if isinstance(msg, HumanMessage):
            user_question = msg.content
            break

    # æå–æœ€ç»ˆç­”æ¡ˆæˆ–ä¸Šä¸‹æ–‡ä½œä¸ºèƒŒæ™¯
    final_answer = None
    for msg in reversed(messages):
        if isinstance(msg, AIMessage):
            try:
                content = msg.content
                if not isinstance(content, str):
                    content = str(content)
                clean_content = re.sub(
                    r"<think>.*?</think>", "", content, flags=re.DOTALL
                )
                decision = json.loads(clean_content)
                if decision.get("action") == "final_answer":
                    final_answer = decision.get("content")
                    break
            except:
                pass

    context_parts = []
    for msg in messages:
        if isinstance(msg, SystemMessage):
            if "Search Result:" in msg.content:
                context_parts.append(msg.content)

    context = (
        "\n\n".join(context_parts[-3:])
        if context_parts
        else "No specific search context."
    )
    background = final_answer if final_answer else context

    try:
        debate_result = run_autogen_debate(user_question or "æœªçŸ¥é—®é¢˜", background)
    except Exception as e:
        logger.error(f"[Debate Node] AutoGen debate failed: {e}")
        debate_result = {
            "debate_transcript": {"error": str(e)},
            "scores": {
                "bull_score": 50,
                "bear_score": 50,
                "final_score": 50,
                "confidence": "low",
            },
            "key_points": {"bull": ["è¾©è®ºæ‰§è¡Œå¤±è´¥"], "bear": ["è¾©è®ºæ‰§è¡Œå¤±è´¥"]},
            "assessment": {"risk_level": "medium", "recommendation": "Hold"},
        }

    final_report = generate_final_report(
        question=user_question,
        base_answer=background,
        debate_result=debate_result,
    )

    return {
        "debate_transcript": debate_result.get("debate_transcript", {}),
        "debate_scores": debate_result.get("scores", {}),
        "debate_key_points": debate_result.get("key_points", {}),
        "debate_assessment": debate_result.get("assessment", {}),
        "final_report": final_report,
    }


def generate_final_report(
    question: Any,
    base_answer: Any,
    debate_result: Dict[str, Any],
) -> str:
    """
    ç”Ÿæˆæœ€ç»ˆç ”åˆ¤æŠ¥å‘Š
    """
    scores = debate_result.get("scores", {})
    key_points = debate_result.get("key_points", {})
    assessment = debate_result.get("assessment", {})

    bull_score = scores.get("bull_score", 50)
    bear_score = scores.get("bear_score", 50)
    final_score = scores.get("final_score", 50)
    confidence = scores.get("confidence", "medium")
    recommendation = assessment.get("recommendation", "Neutral")
    risk_level = assessment.get("risk_level", "medium")

    report_lines = [
        "# åŠå¯¼ä½“è¡Œä¸šç ”åˆ¤æŠ¥å‘Š",
        "",
        "## ä¸€ã€é—®é¢˜å›é¡¾",
        f"**ç”¨æˆ·é—®é¢˜ï¼š** {question}",
        "",
        "## äºŒã€åŸºç¡€åˆ†æ",
        f"{base_answer}",
        "",
        "## ä¸‰ã€å¤šä»£ç†è¾©è®ºè¯„åˆ† (via AutoGen)",
        "",
        f"### ğŸŸ¢ çœ‹å¤šæ–¹è§‚ç‚¹ (å¾—åˆ†: {bull_score}/100)",
    ]

    for i, point in enumerate(key_points.get("bull", [])[:5], 1):
        report_lines.append(f"{i}. {point}")

    report_lines.append("")
    report_lines.append(f"### ğŸ”´ çœ‹ç©ºæ–¹è§‚ç‚¹ (å¾—åˆ†: {bear_score}/100)")
    for i, point in enumerate(key_points.get("bear", [])[:5], 1):
        report_lines.append(f"{i}. {point}")

    report_lines.extend(
        [
            "",
            f"### ğŸ“Š ç»¼åˆè¯„åˆ†: {final_score}/100",
            f"- **ç½®ä¿¡åº¦:** {str(confidence).upper()}",
            f"- **é£é™©ç­‰çº§:** {str(risk_level).upper()}",
            f"- **ç»¼åˆå»ºè®®:** {recommendation}",
            "",
            "## å››ã€ç»“è®º",
        ]
    )

    if final_score >= 70:
        report_lines.append("ç»¼åˆæ¥çœ‹ï¼Œå…¬å¸åŸºæœ¬é¢è‰¯å¥½ï¼ŒæŠ€æœ¯é¢†å…ˆï¼Œå»ºè®®ç§¯æå…³æ³¨ã€‚")
    elif final_score >= 50:
        report_lines.append("ç»¼åˆæ¥çœ‹ï¼Œå…¬å¸æœ‰ä¸€å®šä¼˜åŠ¿ä½†ä¹Ÿå­˜åœ¨é£é™©ï¼Œå»ºè®®è°¨æ…è§‚æœ›ã€‚")
    else:
        report_lines.append("ç»¼åˆæ¥çœ‹ï¼Œå…¬å¸é¢ä¸´è¾ƒå¤§ä¸ç¡®å®šæ€§ï¼Œå»ºè®®å›é¿æˆ–å‡æŒã€‚")

    return "\n".join(report_lines)
